# ==============================================================================
# HONEYPOT DEPLOYMENT — WSL2 + Cloud Compatible
# All configurable values are driven by .env
# Adjust ES_JAVA_OPTS / LS_JAVA_OPTS in .env to match your system RAM:
#   4 GB  → ES=-Xms512m -Xmx512m   LS=-Xms256m -Xmx256m
#   8 GB  → ES=-Xms1g   -Xmx1g     LS=-Xms512m -Xmx512m
#   16 GB → ES=-Xms2g   -Xmx2g     LS=-Xms1g   -Xmx1g
# ==============================================================================

networks:
  honeypot-network:
    driver: bridge
    ipam:
      config:
        - subnet: ${SUBNET}

volumes:
  elasticsearch-data:
    driver: local
  dionaea-data:
    driver: local
  logstash-data:
    driver: local

services:

  # ============================================
  # ELASTICSEARCH
  # ============================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}
    container_name: elasticsearch
    hostname: elasticsearch

    environment:
      - node.name=elasticsearch-node-1
      - cluster.name=honeypot-cluster
      - discovery.type=single-node
      - network.host=0.0.0.0
      - http.port=9200
      - bootstrap.memory_lock=false
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - TZ=${TZ}

    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

    # Bind to 127.0.0.1 — accessible from the host but not from the internet.
    # Container-to-container traffic uses Docker DNS (http://elasticsearch:9200).
    ports:
      - "127.0.0.1:${ELASTICSEARCH_PORT}:9200"

    networks:
      - honeypot-network

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 15
      start_period: 180s

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 2G

  # ============================================
  # LOGSTASH
  # ============================================
  logstash:
    image: docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
    container_name: logstash
    hostname: logstash

    environment:
      - LS_JAVA_OPTS=${LS_JAVA_OPTS}
      - ELASTICSEARCH_HOSTS=${ELASTICSEARCH_HOSTS}
      - TZ=${TZ}
      # All logstash.yml settings passed as env vars — avoids single-file
      # bind-mount failures on WSL2 / Docker Desktop ("not a directory" error).
      - xpack.monitoring.enabled=false
      - xpack.geoip.downloader.enabled=false
      - pipeline.workers=1
      - pipeline.batch.size=125
      - pipeline.batch.delay=50
      - log.level=warn
      - http.enabled=true
      - http.host=0.0.0.0
      - http.port=9600

    volumes:
      - ./elk-stack/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logs:/var/log/honeypots:ro
      - logstash-data:/usr/share/logstash/data

    # Beats input and API bound to localhost only — not internet-facing
    ports:
      - "127.0.0.1:${LOGSTASH_BEATS_PORT}:5044"
      - "127.0.0.1:${LOGSTASH_API_PORT}:9600"

    networks:
      - honeypot-network

    depends_on:
      elasticsearch:
        condition: service_healthy

    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9600 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 1G

  # ============================================
  # KIBANA
  # ============================================
  kibana:
    image: docker.elastic.co/kibana/kibana:${ELASTIC_VERSION}
    container_name: kibana
    hostname: kibana

    environment:
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=5601
      - ELASTICSEARCH_HOSTS=${ELASTICSEARCH_HOSTS}
      - XPACK_SECURITY_ENABLED=false
      - XPACK_MONITORING_ENABLED=false
      - TELEMETRY_ENABLED=false
      - TELEMETRY_OPTIN=false
      # Required in Kibana 8.8+ — prevents savedObjects migration hang on first boot
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=honeypot_platform_enc_key_2026_min32
      # Disable Fleet — heavy background initialisation that delays startup
      - XPACK_FLEET_ENABLED=false
      # Node.js heap cap — increase proportionally if you have more RAM
      - NODE_OPTIONS=--max-old-space-size=512
      - LOGGING_ROOT_LEVEL=warn
      - TZ=${TZ}

    # Localhost-only — SSH-tunnel or webapp proxy for remote access
    ports:
      - "127.0.0.1:${KIBANA_PORT}:5601"

    networks:
      - honeypot-network

    depends_on:
      elasticsearch:
        condition: service_healthy

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 1G

  # ============================================
  # COWRIE SSH / TELNET HONEYPOT
  # ============================================
  cowrie:
    image: cowrie/cowrie:latest
    container_name: cowrie-honeypot
    hostname: srv01

    environment:
      - COWRIE_LOG_PATH=/cowrie/cowrie-git/var/log/cowrie
      - COWRIE_OUTPUT=json
      - TZ=${TZ}

    volumes:
      # Single bind-mount so logs land in ./logs/cowrie/ for Logstash to read.
      # (A second named-volume mount to the same path was removed — it shadowed
      # the bind mount and prevented Logstash from seeing the log files.)
      - ./logs/cowrie:/cowrie/cowrie-git/var/log/cowrie
      - ./data/cowrie/downloads:/cowrie/cowrie-git/var/lib/cowrie/downloads

    # Honeypot ports must be publicly accessible — keep binding to 0.0.0.0
    ports:
      - "${COWRIE_SSH_PORT}:2222"
      - "${COWRIE_TELNET_PORT}:2223"

    networks:
      - honeypot-network

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # DIONAEA MULTI-PROTOCOL HONEYPOT
  # ============================================
  dionaea:
    image: dinotools/dionaea:latest
    container_name: dionaea-honeypot
    hostname: dionaea

    environment:
      - TZ=${TZ}

    volumes:
      - dionaea-data:/opt/dionaea/var
      - ./logs/dionaea:/opt/dionaea/var/log
      - ./data/dionaea/binaries:/opt/dionaea/var/lib/dionaea/binaries

    # Honeypot ports — publicly accessible
    ports:
      - "${DIONAEA_FTP_PORT}:21"
      - "${DIONAEA_DAYTIME_PORT}:42"
      - "${DIONAEA_RPC_PORT}:135"
      - "${DIONAEA_HTTPS_PORT}:443"
      - "${DIONAEA_SMB_PORT}:445"
      - "${DIONAEA_MSSQL_PORT}:1433"
      - "${DIONAEA_MYSQL_PORT}:3306"
      - "${DIONAEA_SIP_PORT}:5060"
      - "${DIONAEA_SIPS_PORT}:5061"

    networks:
      - honeypot-network

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 512M

  # ============================================
  # FLASK HTTP HONEYPOT
  # ============================================
  flask:
    build:
      context: ./honeypots/flask-honeypot
      dockerfile: Dockerfile
    container_name: flask-honeypot
    hostname: webserver

    environment:
      - LOG_LEVEL=${LOG_LEVEL}
      - TZ=${TZ}
      - PYTHONUNBUFFERED=1

    volumes:
      - ./logs/flask:/app/logs

    # Honeypot port — publicly accessible
    ports:
      - "${FLASK_HTTP_PORT}:8080"

    networks:
      - honeypot-network

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # WEB MANAGEMENT DASHBOARD
  # ============================================
  webapp:
    build:
      context: ./webapp
      dockerfile: Dockerfile
    image: honeypot/webapp:latest
    pull_policy: build
    container_name: webapp
    hostname: webapp

    environment:
      - FLASK_ENV=${FLASK_ENV}
      - ELASTICSEARCH_URL=${ELASTICSEARCH_URL}
      - LOG_LEVEL=${LOG_LEVEL}
      - PYTHONUNBUFFERED=1
      - TZ=${TZ}
      # Must match the host project name so 'docker compose up' from inside the
      # container joins the existing stack instead of creating a new network.
      - COMPOSE_PROJECT_NAME=honeypot-project

    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - .:/app/project:ro

    # Dashboard is publicly accessible (restrict with firewall on cloud)
    ports:
      - "${WEBAPP_PORT}:5000"

    networks:
      - honeypot-network

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 256M

  # ============================================
  # NGROK — INTERNET EXPOSURE (optional, WSL2 only)
  # Only starts when the "expose" profile is active.
  #   make expose            → start tunnels
  #   make tunnel-status     → show public URLs
  #
  # NOT needed on a cloud VPS (direct public IP).
  # Requires NGROK_AUTHTOKEN in .env
  # ============================================
  ngrok:
    image: ngrok/ngrok:latest
    container_name: ngrok-tunnel
    profiles: ["expose"]
    restart: unless-stopped

    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN:-}

    command: >
      start --all
      --config /etc/ngrok.yml
      --authtoken ${NGROK_AUTHTOKEN:-}

    volumes:
      - ./ngrok.yml:/etc/ngrok.yml:ro

    ports:
      - "127.0.0.1:4040:4040"   # ngrok web inspector — localhost only

    networks:
      - honeypot-network

    depends_on:
      - flask

    deploy:
      resources:
        limits:
          memory: 128M
